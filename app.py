import streamlit as st
import os
import requests 
from bs4 import BeautifulSoup 
from openai import AzureOpenAI
from dotenv import load_dotenv
import urllib.parse

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.title("ğŸ“° ë„¤ì´ë²„ ì¸ê¸° ë‰´ìŠ¤ ê²€ìƒ‰ ì±—ë´‡")
st.markdown("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì‹œë©´ ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ì¸ê¸° ë‰´ìŠ¤ **3ê°œ**ë¥¼ ë½‘ì•„ ë“œë¦½ë‹ˆë‹¤.")

def get_naver_popular_news(keyword):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¸ê¸°ìˆœ ë‰´ìŠ¤ 3ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # URL ì¸ì½”ë”© ì¶”ê°€
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort=0&photo=0&field=0&pd=0&ds=&de=&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    } 
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() 

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ìŠ¤í¬ë¦°ìƒ·ì—ì„œ í™•ì¸ëœ êµ¬ì¡°: div.sds-comps-vertical-layout ë‚´ë¶€ì˜ í•­ëª©ë“¤
        news_items = soup.select('div.sds-comps-vertical-layout.sds-comps-full-layout')
        
        if not news_items:
            # ëŒ€ì²´ ì„ íƒì
            news_items = soup.select('div.sds-comps-base-layout') or \
                        soup.select('ul.list_news > li.bx')
        
        if not news_items:
            return []

        top_3_news = []
        
        for item in news_items:
            if len(top_3_news) >= 3:
                break
            
            try:
                # ìŠ¤í¬ë¦°ìƒ· êµ¬ì¡°ì— ë§ì¶˜ ì„ íƒì
                # 1. ë§í¬ ì¶”ì¶œ: a íƒœê·¸ì—ì„œ href ì†ì„±
                link_tag = item.select_one('a[href*="naver.com"]')
                if not link_tag:
                    continue
                
                link = link_tag.get('href', '')
                if not link:
                    continue
                
                # 2. ì œëª© ì¶”ì¶œ: span.sds-comps-text ë‚´ë¶€ì˜ í…ìŠ¤íŠ¸
                title_tag = item.select_one('span.sds-comps-text.sds-comps-text-ellipsis')
                if not title_tag:
                    title_tag = item.select_one('span.sds-comps-text')
                
                if title_tag:
                    title = title_tag.get_text(strip=True)
                else:
                    # a íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    title = link_tag.get_text(strip=True)
                
                # 3. ì–¸ë¡ ì‚¬ ì¶”ì¶œ
                source_tag = item.select_one('a.info.press') or \
                           item.select_one('a.info') or \
                           item.select_one('div.sds-comps-profile span')
                
                source = source_tag.get_text(strip=True) if source_tag else "ì¶œì²˜ ë¶ˆëª…"
                
                if title and link and len(title) > 5:  # ì œëª©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸
                    top_3_news.append({
                        "rank": len(top_3_news) + 1,
                        "title": title,
                        "link": link,
                        "source": source
                    })
                    
            except Exception as e:
                print(f"ë‰´ìŠ¤ ì•„ì´í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        return top_3_news

    except requests.exceptions.RequestException as e:
        return f"ğŸš¨ ì›¹ ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}"
    except Exception as e:
        return f"ğŸš¨ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì„ íƒì‚¬í•­)
try:
    client = AzureOpenAI(
        api_key=os.getenv("AZURE_OAI_KEY"),
        api_version="2024-05-01-preview",
        azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
    )
except Exception as e:
    st.warning("Azure OpenAI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    client = None

# ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš” (ì˜ˆ: ì‚¼ì„±, AI ë°˜ë„ì²´)"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ë‰´ìŠ¤ ê²€ìƒ‰ ë° ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            keyword = prompt.strip()
            news_results = get_naver_popular_news(keyword)
        
        # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
        if isinstance(news_results, str):
            assistant_reply = news_results
        elif not news_results:
            assistant_reply = f"ğŸ‘‰ **'{keyword}'**ì— ëŒ€í•œ ì¸ê¸° ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
        else:
            reply_lines = [f"ğŸŒŸ **'{keyword}'**ì— ëŒ€í•œ ë„¤ì´ë²„ ì¸ê¸° ë‰´ìŠ¤ Top {len(news_results)} ì…ë‹ˆë‹¤:\n"]
            for news in news_results:
                reply_lines.append(f"**{news['rank']}.** [{news['title']}]({news['link']})")
                reply_lines.append(f"   *ì¶œì²˜: {news['source']}*\n")
                
            assistant_reply = "\n".join(reply_lines)
            
        st.markdown(assistant_reply)

    # AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})