import streamlit as st
import os
import requests 
from bs4 import BeautifulSoup 
from openai import AzureOpenAI
from dotenv import load_dotenv
import urllib.parse

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

st.title("ğŸ“° ë„¤ì´ë²„ ì¸ê¸° ë‰´ìŠ¤ ê²€ìƒ‰ ì±—ë´‡")
st.markdown("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì‹œë©´ ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ ê´€ë ¨ ì¸ê¸° ë‰´ìŠ¤ **3ê°œ**ë¥¼ ë½‘ì•„ ë“œë¦½ë‹ˆë‹¤.")

def get_naver_popular_news(keyword):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¸ê¸°ìˆœ ë‰´ìŠ¤ 3ê°œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    encoded_keyword = urllib.parse.quote(keyword)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_keyword}&sm=tab_opt&sort=0&photo=0&field=0&pd=0&ds=&de=&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    } 
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status() 

        soup = BeautifulSoup(response.text, 'html.parser')
        
        news_items = soup.select('div.sds-comps-vertical-layout.sds-comps-full-layout')
        
        if not news_items:
            news_items = soup.select('div.sds-comps-base-layout') or \
                        soup.select('ul.list_news > li.bx')
        
        if not news_items:
            return []

        top_3_news = []
        
        for item in news_items:
            if len(top_3_news) >= 3:
                break
            
            try:
                link_tag = item.select_one('a[href*="naver.com"]')
                if not link_tag:
                    continue
                
                link = link_tag.get('href', '')
                if not link:
                    continue
                
                title_tag = item.select_one('span.sds-comps-text.sds-comps-text-ellipsis')
                if not title_tag:
                    title_tag = item.select_one('span.sds-comps-text')
                
                if title_tag:
                    title = title_tag.get_text(strip=True)
                else:
                    title = link_tag.get_text(strip=True)
                
                source_tag = item.select_one('a.info.press') or \
                           item.select_one('a.info') or \
                           item.select_one('div.sds-comps-profile span')
                
                source = source_tag.get_text(strip=True) if source_tag else "ì¶œì²˜ ë¶ˆëª…"
                
                # ê¸°ì‚¬ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ (ìš”ì•½ìš©)
                summary_tag = item.select_one('div.news_dsc') or \
                             item.select_one('div.dsc_txt_wrap') or \
                             item.select_one('a.dsc_txt_wrap')
                
                summary = summary_tag.get_text(strip=True) if summary_tag else ""
                
                if title and link and len(title) > 5:
                    top_3_news.append({
                        "rank": len(top_3_news) + 1,
                        "title": title,
                        "link": link,
                        "source": source,
                        "summary": summary
                    })
                    
            except Exception as e:
                print(f"ë‰´ìŠ¤ ì•„ì´í…œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        return top_3_news

    except requests.exceptions.RequestException as e:
        return f"ğŸš¨ ì›¹ ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {e}"
    except Exception as e:
        return f"ğŸš¨ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


def get_article_content(url):
    """
    ê¸°ì‚¬ URLì—ì„œ ë³¸ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì„ íƒì
        article_body = soup.select_one('#dic_area') or \
                      soup.select_one('#articeBody') or \
                      soup.select_one('.article_body') or \
                      soup.select_one('#newsEndContents')
        
        if article_body:
            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
            for tag in article_body.select('script, style, iframe'):
                tag.decompose()
            return article_body.get_text(strip=True)
        
        return None
        
    except Exception as e:
        print(f"ê¸°ì‚¬ ë‚´ìš© ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None


def summarize_article_with_ai(article_content, user_query=""):
    """
    Azure OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
    """
    try:
        if user_query:
            prompt = f"ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ì½ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.\n\nì§ˆë¬¸: {user_query}\n\nê¸°ì‚¬ ë‚´ìš©:\n{article_content[:3000]}"
        else:
            prompt = f"ë‹¤ìŒ ê¸°ì‚¬ë¥¼ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{article_content[:3000]}"
        
        response = client.chat.completions.create(
            model=os.getenv("AZURE_OAI_DEPLOYMENT", "gpt-4"),
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ê³  ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


def find_related_articles(news_list, keyword):
    """
    ë‰´ìŠ¤ ëª©ë¡ì—ì„œ íŠ¹ì • í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    related = []
    keyword_lower = keyword.lower()
    
    for news in news_list:
        title_lower = news['title'].lower()
        summary_lower = news.get('summary', '').lower()
        
        if keyword_lower in title_lower or keyword_lower in summary_lower:
            related.append(news)
    
    return related


# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
try:
    client = AzureOpenAI(
        api_key=os.getenv("AZURE_OAI_KEY"),
        api_version="2024-05-01-preview",
        azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
    )
    ai_available = True
except Exception as e:
    st.warning("âš ï¸ Azure OpenAI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”. AI ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    client = None
    ai_available = False

# ëŒ€í™”ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ìµœê·¼ ê²€ìƒ‰í•œ ë‰´ìŠ¤ ì €ì¥
if "recent_news" not in st.session_state:
    st.session_state.recent_news = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì§ˆë¬¸í•´ì£¼ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        prompt_lower = prompt.lower()
        
        # 1. ê¸°ì‚¬ ìš”ì•½ ìš”ì²­ ê°ì§€
        if any(word in prompt_lower for word in ['ìš”ì•½', 'ìš”ì•½í•´', 'ì •ë¦¬', 'ì •ë¦¬í•´']):
            if not st.session_state.recent_news:
                assistant_reply = "ë¨¼ì € ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”. ì˜ˆ: 'ì‚¼ì„±' ë˜ëŠ” 'AI ë°˜ë„ì²´'"
            elif not ai_available:
                assistant_reply = "AI ìš”ì•½ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ Azure OpenAI ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
            else:
                with st.spinner("ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    summaries = []
                    for news in st.session_state.recent_news:
                        article_content = get_article_content(news['link'])
                        if article_content:
                            summary = summarize_article_with_ai(article_content)
                            summaries.append(f"**{news['rank']}. {news['title']}**\n{summary}\n")
                        else:
                            summaries.append(f"**{news['rank']}. {news['title']}**\n(ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤)\n")
                    
                    assistant_reply = "ğŸ“ **ê¸°ì‚¬ ìš”ì•½**\n\n" + "\n".join(summaries)
        
        # 2. ê´€ë ¨ ê¸°ì‚¬ ê²€ìƒ‰ ìš”ì²­ ê°ì§€
        elif 'ê´€ë ¨' in prompt_lower and ('ê¸°ì‚¬' in prompt_lower or 'ë‰´ìŠ¤' in prompt_lower):
            if not st.session_state.recent_news:
                assistant_reply = "ë¨¼ì € ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
            else:
                # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
                words = prompt.split()
                search_keyword = None
                for i, word in enumerate(words):
                    if 'ê´€ë ¨' in word and i > 0:
                        search_keyword = words[i-1].strip('ì´ë‘').strip()
                        break
                
                if search_keyword:
                    related = find_related_articles(st.session_state.recent_news, search_keyword)
                    if related:
                        reply_lines = [f"ğŸ” **'{search_keyword}'** ê´€ë ¨ ê¸°ì‚¬:\n"]
                        for news in related:
                            reply_lines.append(f"**{news['rank']}.** [{news['title']}]({news['link']})")
                            reply_lines.append(f"   *ì¶œì²˜: {news['source']}*\n")
                        assistant_reply = "\n".join(reply_lines)
                    else:
                        assistant_reply = f"'{search_keyword}'ì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    assistant_reply = "ì–´ë–¤ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì‚¬ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”? ì˜ˆ: 'AIë‘ ê´€ë ¨ëœ ê¸°ì‚¬ê°€ ìˆì–´?'"
        
        # 3. ì¼ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰
        else:
            with st.spinner("ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                keyword = prompt.strip()
                news_results = get_naver_popular_news(keyword)
            
            if isinstance(news_results, str):
                assistant_reply = news_results
            elif not news_results:
                assistant_reply = f"ğŸ‘‰ **'{keyword}'**ì— ëŒ€í•œ ì¸ê¸° ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
            else:
                # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
                st.session_state.recent_news = news_results
                
                reply_lines = [f"ğŸŒŸ **'{keyword}'**ì— ëŒ€í•œ ë„¤ì´ë²„ ì¸ê¸° ë‰´ìŠ¤ Top {len(news_results)} ì…ë‹ˆë‹¤:\n"]
                for news in news_results:
                    reply_lines.append(f"**{news['rank']}.** [{news['title']}]({news['link']})")
                    reply_lines.append(f"   *ì¶œì²˜: {news['source']}*\n")
                
                if ai_available:
                    reply_lines.append("\nğŸ’¡ **ì´ë ‡ê²Œ ë¬¼ì–´ë³´ì„¸ìš”:**")
                    reply_lines.append("- 'ì´ ê¸°ì‚¬ ìš”ì•½í•´ì¤˜'")
                    reply_lines.append("- 'AIë‘ ê´€ë ¨ëœ ê¸°ì‚¬ê°€ ìˆì–´?'")
                
                assistant_reply = "\n".join(reply_lines)
            
        st.markdown(assistant_reply)

    # AI ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": assistant_reply})